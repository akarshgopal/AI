{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from IPython.display import clear_output, display, Math, Latex\n",
    "from atlas_ml import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Datasets/Classification/Titanic/train.csv')\n",
    "dataset = dataset.fillna(0)\n",
    "data = dataset.values.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('Datasets/Classification/Titanic/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(name):\n",
    "    if re.search('Mr\\.', name):\n",
    "        return 1\n",
    "    elif re.search('Mrs\\.', name):\n",
    "        return 2\n",
    "    elif re.search('Miss\\.', name):\n",
    "        return 3\n",
    "    else:\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_title('Braund, Mr Owen Harris')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pass_id = data[0]\n",
    "Y = one_hot(np.expand_dims(data[1],0),2)\n",
    "Pclass = data[2]\n",
    "Title = [get_title(i) for i in data[3]]\n",
    "Sex = [1*int(i=='male') for i in data[4] ] #Source of error because NaN values are default assigned 0.\n",
    "Age = data[5]\n",
    "SibSp = data[6]\n",
    "Parch = data[7]\n",
    "#Ticket = [i]  -> probably irrelevant or redundant with class, fare etc\n",
    "Fare = data[9]\n",
    "#Cabin = [int(i[])] -> too many Nan\n",
    "Embarked = [1*int(i=='S')+2*int(i=='C')+3*int(i=='Q') for i in data[11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# degree of polynomial features\n",
    "d = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = np.vstack([normalize(i) for i in [Pclass,Title,Sex,Age,SibSp,Parch,Fare,Embarked]])\n",
    "size = X.shape[1]\n",
    "#X_train = X[:,:int(size*0.9)].astype('Float64')\n",
    "#Y_train = Y[:,:int(size*0.9)].astype('Float64')\n",
    "X_train = X[:,int(size*0.1):].astype('Float64')\n",
    "Y_train = Y[:,int(size*0.1):].astype('Float64')\n",
    "#X_train = X.astype('Float64')\n",
    "#Y_train = Y.astype('Float64')\n",
    "\n",
    "PX_train = (polynom_features(X_train,d))\n",
    "#X_val = X[:,int(size*0.9):].astype('Float64')\n",
    "#Y_val = Y[:,int(size*0.9):].astype('Float64')\n",
    "X_val = X[:,:int(size*0.1)].astype('Float64')\n",
    "Y_val = Y[:,:int(size*0.1)].astype('Float64')\n",
    "\n",
    "PX_val = (polynom_features(X_val,d))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_in = np.shape(PX_train)[0]\n",
    "n_out = np.shape(Y_train)[0]\n",
    "log_reg = Logistic(n_in,n_out,CE_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 150\n",
    "lr = 0.01\n",
    "lr_decay = 1\n",
    "batch_size = 16\n",
    "beta = 0.99\n",
    "\n",
    "#regularization parameter labmda\n",
    "reg_lamda = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train(log_reg, PX_train, Y_train, PX_val, Y_val, model_accuracy, n_epochs, batch_size, lr, lr_decay, beta, reg_lamda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HL_net:\n",
    "    def __init__(self, X_size, Y_size, lossfn):\n",
    "        self.L1 = layer(X_size, 32, relu)\n",
    "        self.L2 = layer(32, 16, relu)        \n",
    "        self.L3 = layer(16, Y_size, softmax)\n",
    "        self.lossfn = lossfn()\n",
    "        \n",
    "    def f_pass(self, X):\n",
    "        A1 = self.L1.forward(X)\n",
    "        A2 = self.L2.forward(A1)\n",
    "        A3 = self.L3.forward(A2)\n",
    "        self.H = A3\n",
    "        return self.H\n",
    "    \n",
    "    def back_prop(self,X,Y, batch_size,reg_lambda):\n",
    "        m = batch_size\n",
    "        \n",
    "        self.loss = self.lossfn.get_loss(self.H,Y)\n",
    "        dL_dZ = self.lossfn.diff(self.H,Y)\n",
    "        \n",
    "        self.L3.out_grad(dL_dZ, self.L2.A, m)\n",
    "        self.L2.grad(self.L3.dZ, self.L3.W, self.L1.A, m)\n",
    "        self.L1.grad(self.L2.dZ, self.L2.W, X, m)\n",
    "    \n",
    "    def optim(self, lr, beta):\n",
    "        self.L1.step(lr, beta)\n",
    "        self.L2.step(lr, beta)\n",
    "        self.L3.step(lr, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_in = np.shape(X_train)[0]\n",
    "n_out = np.shape(Y_train)[0]\n",
    "\n",
    "#This is the new 'model', so bin_class will be passed to train()\n",
    "bin_clas = HL_net(n_in,n_out,CE_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 500\n",
    "lr = 0.005\n",
    "lr_decay = 0.9\n",
    "batch_size = 16\n",
    "beta = 0.99\n",
    "\n",
    "#regularization parameter labmda\n",
    "reg_lamda = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(bin_clas, X_train, Y_train, X_val, Y_val, model_accuracy, n_epochs, batch_size, lr, beta, reg_lamda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Datasets/Classification/Titanic/test.csv')\n",
    "dataset = dataset.fillna(0)\n",
    "data = dataset.values.T\n",
    "Pass_id = data[0]\n",
    "Pclass = data[1]\n",
    "Title = [get_title(i) for i in data[2]]\n",
    "Sex = [1*int(i=='male') for i in data[3] ]\n",
    "Age = data[4]\n",
    "SibSp = data[5]\n",
    "Parch = data[6]\n",
    "#Ticket = [i]  -> probably irrelevant or redundant with class, fare etc\n",
    "Fare = data[8]\n",
    "#Cabin = [int(i[])] -> too many Nan\n",
    "Embarked = [1*int(i=='S')+2*int(i=='C')+3*int(i=='Q') for i in data[10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test = np.vstack([normalize(i) for i in [Pclass,Title,Sex,Age,SibSp,Parch,Fare,Embarked]]).astype('Float64')\n",
    "PX_test = polynom_features(X_test,d)\n",
    "H = inv_one_hot(bin_clas.f_pass(PX_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'PassengerId':Pass_id.flatten(),'Survived':H.flatten().astype('int')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onlinepub",
   "language": "python",
   "name": "testenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
