{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0: The Data\n",
    "\n",
    "For Basic classification we just use Kaggle's Spaceship Titanic dataset. It's a simple dataset with a few features and a binary label.\n",
    "Download from: https://www.kaggle.com/competitions/spaceship-titanic/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the data briefly, see summary, histograms, ranges, correlations, etc.\n",
    "\n",
    "The goal here is to get a feel for the data, and to see if there are any obvious issues with it.\n",
    "Also we prepare the data for learning by doing some basic preprocessing like assigning numerical labels to categorical columns, removing NaNs, imputing values if needed, and normalizing ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/spaceship-titanic/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a common sense POV, passengerID shouldn't affect the passenger's survival, unless it's a proxy for some feature that isn't in the dataset. So we won't drop it just yet.\n",
    "\n",
    "Our 0 / 1 classification label here is Transported. Our objective is to predict whether a passenger was transported or not given the other features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for categorical columns show set of unique values \n",
    "train_df.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert categorical data to numerical integer codes\n",
    "corr_df = train_df.copy()\n",
    "for col in corr_df.columns:\n",
    "    if corr_df[col].dtype == 'object' or 'bool':\n",
    "        corr_df[col] = corr_df[col].astype('category').cat.codes\n",
    "    else:\n",
    "        # normalize data by column to -1 to 1 per column\n",
    "        corr_df[col] = (corr_df[col] - corr_df[col].mean()) / corr_df[col].std()\n",
    "\n",
    "print(corr_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "correlation_matrix = corr_df.corr(method='pearson')\n",
    "# plot heatmap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix Heatmap')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CryoSleep seems to be decently correlated with Transported, so we should expect it to be a major feature in our model.\n",
    "RoomService seems to be negatively correlated with Transported, so we should expect it to be a major feature in our model.\n",
    "\n",
    "Anyway, we're not hand engineering stuff here. The goal is to try out some basic classic ML approaches for classification and see how well they work. Less goo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train / val split 80:20 randomly\n",
    "df = corr_df.copy()\n",
    "\n",
    "# Set a seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate an array of random indices for shuffling\n",
    "indices = np.arange(len(df))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# Calculate the split index\n",
    "split_index = int(0.8 * len(df))\n",
    "\n",
    "# Split the DataFrame\n",
    "train_df_split = df.iloc[indices[:split_index]]\n",
    "val_df = df.iloc[indices[split_index:]]\n",
    "\n",
    "# Reset the index in the resulting DataFrames\n",
    "train_df_split.reset_index(drop=True, inplace=True)\n",
    "val_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Get train df splits labels and val df's labels\n",
    "train_labels = train_df_split['Transported']\n",
    "val_labels = val_df['Transported']\n",
    "train_df_split=train_df_split.drop(columns=['Transported'])\n",
    "val_df=val_df.drop(columns=['Transported'])\n",
    "\n",
    "# Print the shapes of the resulting DataFrames\n",
    "print(\"Train set shape:\", train_df_split.shape)\n",
    "print(\"Validation set shape:\", val_df.shape)\n",
    "print(\"train_labels\", train_labels.shape)\n",
    "print(\"val_labels\", val_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Good Ol' Machine Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1: K Nearest Neighbours\n",
    "\n",
    "K Nearest Neighbours works by classifying a given point in an N-D space based on its k nearest neighbours using some distance metric, usually the euclidian metric, i.e. L2-norm. This might be problematic with categorical features because how exactly does distance play a part there? for e.g. the planet category is earth, trappist etc. putting these on a numerical axis linearly makes little sense.. but let's see how our approaches handle them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k nearest neighbours\n",
    "class KNNClassifier:\n",
    "    def __init__(self, X_train: pd.DataFrame, y_train: pd.DataFrame, k=3, distance_metric='euclidean'):\n",
    "        self.k = k\n",
    "        self.distance_metric = distance_metric\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "    def _calculate_distance(self, point1: np.array, point2: np.array):\n",
    "        # The square root of the sum of squares of the distances in each axis\n",
    "        # This will be sensitive to the largest distance (since it gets squared)\n",
    "        if self.distance_metric == 'euclidean':\n",
    "            return np.sqrt(np.sum((point1 - point2) ** 2))\n",
    "        # The sum of absolute distances on each axis\n",
    "        elif self.distance_metric == 'manhattan':\n",
    "            return np.sum(np.abs(point1 - point2))\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported distance metric\")\n",
    "\n",
    "    def predict(self, X_test: np.array):\n",
    "        \"\"\" \n",
    "            X_test is of the form: [point1, point2,...pointN]\n",
    "        \"\"\"        \n",
    "        predictions = []\n",
    "        for test_point in tqdm.tqdm(X_test, desc='Calculating distances', unit='point'):\n",
    "            # Calculate distances to all training points\n",
    "            distances = np.array([self._calculate_distance(test_point, train_point) for train_point in self.X_train])\n",
    "\n",
    "            # Get indices of k-nearest neighbors\n",
    "            k_nearest_indices = np.argsort(distances)[:self.k]\n",
    "\n",
    "            # Get the corresponding labels of k-nearest neighbors\n",
    "            k_nearest_labels = self.y_train[k_nearest_indices]\n",
    "\n",
    "            # Find the most common class among the k-nearest neighbors\n",
    "            predicted_label = np.argmax(np.bincount(k_nearest_labels))\n",
    "\n",
    "            predictions.append(predicted_label)\n",
    "\n",
    "        return np.array(predictions)\n",
    "\n",
    "# Create and train the KNN classifier with Manhattan distance\n",
    "knn_classifier_manhattan = KNNClassifier(train_df_split.values, train_labels.values, k=3, distance_metric='manhattan')\n",
    "predictions_manhattan = knn_classifier_manhattan.predict(val_df.values)\n",
    "\n",
    "knn_classifier_euclidean = KNNClassifier(train_df_split.values, train_labels.values, k=3, distance_metric='euclidean')\n",
    "predictions_euclidean = knn_classifier_euclidean.predict(val_df.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Accuracy:\n",
    "We just subtract predictions from the labels, take the absolute value and calculate the mean. Subtracting this mean from 1 should give us a 0-1 accuracy metric. i.e 1 implies 100%, 0 implies 0%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manhattan_accuracy = 1-abs(predictions_manhattan - val_labels).mean()\n",
    "euclidean_accuracy = 1-abs(predictions_euclidean - val_labels).mean()\n",
    "\n",
    "print(\"manhattan accuracy\", manhattan_accuracy)\n",
    "print(\"euclidean accuracy\", euclidean_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Euclidean metric seems to be almost as good as random.. This is weird, I would've expected somewhat better performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "The confusion matrix is a visualisation of how many true positives, false positives, true negatives and false negatives our model predicts.\n",
    "It is useful for getting a sense of how wrong our model is, and where it might be going wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "def plot_confusion_matrix(pred, labels):\n",
    "    conf_matrix = np.zeros((2, 2))\n",
    "    for i in range(len(labels)):\n",
    "        conf_matrix[labels[i], pred[i]] += 1\n",
    "\n",
    "    # Plot the confusion matrix using seaborn\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='g', cmap='Blues', xticklabels=['Predicted 0', 'Predicted 1'], yticklabels=['Actual 0', 'Actual 1'])\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title('Confusion Matrix Manhattan')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(predictions_manhattan, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(predictions_euclidean, val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: Support Vector Machines\n",
    "\n",
    "Basic operating principle: Draw a hyperplane between the points that maximises sum of distances of the points from the hyperplane. Applying radial basis functions or polynomials can increase the complexity of seperation. Picture it as embedding the data points in a more complicated manifold and cutting it across with a hyperplane to seperate the points. SVMs offer a neat way to do this using the kernel trick. https://medium.com/@zxr.nju/what-is-the-kernel-trick-why-is-it-important-98a98db0961d\n",
    "\n",
    "## Extra work: compare with scikit learn's SVM, and improve our implementation\n",
    "https://scikit-learn.org/stable/modules/svm.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add -1 to all zeros in labels to prep for hinge loss\n",
    "train_labels_hinge = train_labels.copy()\n",
    "train_labels_hinge[train_labels_hinge == 0] = -1\n",
    "\n",
    "val_labels_hinge = val_labels.copy()\n",
    "val_labels_hinge[val_labels_hinge == 0] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM:\n",
    "    def __init__(self, learning_rate=0.01, lambda_param=0.001, num_epochs=1000, kernel='linear', degree=2, gamma=1.0):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lambda_param = lambda_param\n",
    "        self.num_epochs = num_epochs\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.kernel = kernel\n",
    "        self.degree = degree\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def _apply_kernel(self, X):\n",
    "        if self.kernel == 'linear':\n",
    "            return X\n",
    "        elif self.kernel == 'polynomial':\n",
    "            return X ** self.degree\n",
    "        elif self.kernel == 'rbf':\n",
    "            return np.exp(-self.gamma * np.linalg.norm(X - X[:, np.newaxis], axis=2) ** 2)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid kernel. Supported kernels are 'linear', 'polynomial', and 'rbf'.\")\n",
    "\n",
    "    def _hinge_loss(self, X, y):\n",
    "        scores = 1 - y * (np.dot(X, self.weights) + self.bias)\n",
    "        return np.maximum(0, scores)\n",
    "\n",
    "    def _gradient_descent_step(self, X, y):\n",
    "        hinge_loss = self._hinge_loss(X, y)\n",
    "        hinge_loss[hinge_loss > 0] = 1  # Binary indicator function for hinge loss\n",
    "        gradient = -np.dot(X.T, y * hinge_loss) / len(y)\n",
    "        gradient_reg = self.lambda_param * self.weights  # Regularization term\n",
    "        self.weights -= self.learning_rate * (gradient + gradient_reg)\n",
    "        # Update bias\n",
    "        self.bias -= self.learning_rate * np.sum(y * hinge_loss) / len(y)\n",
    "        return hinge_loss\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Apply the selected kernel\n",
    "        X_transformed = self._apply_kernel(X)\n",
    "\n",
    "        # Initialize weights and bias\n",
    "        self.weights = np.zeros(X_transformed.shape[1])\n",
    "        self.bias = 0\n",
    "\n",
    "        # Training loop\n",
    "        for _ in tqdm.tqdm(range(self.num_epochs), desc='Training', unit='epoch'):\n",
    "            self._gradient_descent_step(X_transformed, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Apply the selected kernel to the input for prediction\n",
    "        X_transformed = self._apply_kernel(X)\n",
    "        return np.sign(np.dot(X_transformed, self.weights) + self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVM()\n",
    "svm.fit(train_df_split.values, train_labels_hinge.values)\n",
    "predictions_svm = svm.predict(val_df.values)\n",
    "predictions_svm[predictions_svm == -1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_accuracy = 1-abs(predictions_svm - val_labels).mean()\n",
    "print(\"svm accuracy\", svm_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(np.array(predictions_svm, dtype='int8'), val_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3: Decision Trees\n",
    "\n",
    "We're going to breeze through this and just use sklearn for now. We can come back and implement it in numpy later.\n",
    "Basically it is going column by column, checking how well each column predicts the label, then selecting the most predictive column as a rule, using some relevant if-condition and bifurcating the rows based on that into yes / no -> then repeating the process with other columns for each bifurcation.\n",
    "\n",
    "Random forests are just taking N-trees with random params and ensembling the outputs to \"average\" into a better output.\n",
    "\n",
    "Gradient boosting is using a sub-decision tree to predict the \"error\" in the main decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create an instance of the DecisionTreeClassifier\n",
    "tree_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "tree_classifier.fit(train_df_split, train_labels)\n",
    "\n",
    "# Predict on the validation data\n",
    "predictions_tree = tree_classifier.predict(val_df)\n",
    "\n",
    "# Calculate the accuracy\n",
    "tree_accuracy = (predictions_tree == val_labels).mean()\n",
    "print(\"Decision Tree accuracy:\", tree_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3a: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create an instance of the RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "rf_classifier.fit(train_df_split, train_labels)\n",
    "\n",
    "# Predict on the validation data\n",
    "predictions_rf = rf_classifier.predict(val_df)\n",
    "\n",
    "# Calculate the accuracy\n",
    "rf_accuracy = (predictions_rf == val_labels).mean()\n",
    "print(\"Random Forest accuracy:\", rf_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3b: Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Create an instance of the GradientBoostingClassifier\n",
    "gb_classifier = GradientBoostingClassifier()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "gb_classifier.fit(train_df_split, train_labels)\n",
    "\n",
    "# Predict on the validation data\n",
    "predictions_gb = gb_classifier.predict(val_df)\n",
    "\n",
    "# Calculate the accuracy\n",
    "gb_accuracy = (predictions_gb == val_labels).mean()\n",
    "print(\"Gradient Boosting accuracy:\", gb_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "# Import the necessary module\n",
    "# Create an instance of the XGBoost classifier\n",
    "xgb_classifier = xgb.XGBClassifier()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "xgb_classifier.fit(train_df_split, train_labels)\n",
    "\n",
    "# Predict on the validation data\n",
    "predictions_xgb = xgb_classifier.predict(val_df)\n",
    "\n",
    "# Calculate the accuracy\n",
    "xgb_accuracy = (predictions_xgb == val_labels).mean()\n",
    "print(\"XGBoost accuracy:\", xgb_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're getting close to 0.82 with very little effort. How can we improve it?\n",
    "- Explore feature importance\n",
    "- "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-bootcamp-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
